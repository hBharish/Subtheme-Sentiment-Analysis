{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMj9mYHsqcj2KgWekoxb5QA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hBharish/Subtheme-Sentiment-Analysis/blob/main/Subtheme_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H259LKfI7NXP"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from re import escape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Load dataset\n",
        "df = pd.read_csv('Evaluation-dataset.csv')\n",
        "df = df.dropna(subset=[df.columns[1]])\n",
        "\n",
        "# Initialize lists to store reviews and labels\n",
        "reviews = []\n",
        "unique_labels = set()\n",
        "llb = []\n",
        "\n",
        "# Iterate over each row in the dataset\n",
        "for row in df.itertuples(index=False):\n",
        "    temp_labels = []\n",
        "    for item in row[1:]:\n",
        "        if pd.notnull(item):\n",
        "            if \"positive\" in item.lower() or \"negative\" in item.lower():\n",
        "                unique_labels.add(item.lower())\n",
        "                temp_labels.append(item.lower())\n",
        "    if temp_labels:\n",
        "        reviews.append(row[0])\n",
        "        llb.append(temp_labels)\n",
        "\n",
        "# Convert labels set to list\n",
        "unique_labels = list(unique_labels)\n",
        "print(len(reviews))\n",
        "\n",
        "# Create DataFrame with reviews and unique labels\n",
        "df_new = pd.DataFrame(columns=['reviews'] + unique_labels)\n",
        "\n",
        "# Set values in DataFrame based on labels presence\n",
        "for review, labels in zip(reviews, llb):\n",
        "    row_values = [1 if label in labels else 0 for label in unique_labels]\n",
        "    df_new.loc[len(df_new)] = [review] + row_values\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "df_new.to_csv('reviews_with_labels.csv', index=False)\n",
        "\n",
        "print(\"CSV file saved successfully.\")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "l9UGWPqb7eR2",
        "outputId": "8c7813bb-1881-4038-b0b3-5283a938c224"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Load dataset\\ndf = pd.read_csv(\\'Evaluation-dataset.csv\\')\\ndf = df.dropna(subset=[df.columns[1]])\\n\\n# Initialize lists to store reviews and labels\\nreviews = []\\nunique_labels = set()\\nllb = []\\n\\n# Iterate over each row in the dataset\\nfor row in df.itertuples(index=False):\\n    temp_labels = []\\n    for item in row[1:]:\\n        if pd.notnull(item):\\n            if \"positive\" in item.lower() or \"negative\" in item.lower():\\n                unique_labels.add(item.lower())\\n                temp_labels.append(item.lower())\\n    if temp_labels:\\n        reviews.append(row[0])\\n        llb.append(temp_labels)\\n\\n# Convert labels set to list\\nunique_labels = list(unique_labels)\\nprint(len(reviews))\\n\\n# Create DataFrame with reviews and unique labels\\ndf_new = pd.DataFrame(columns=[\\'reviews\\'] + unique_labels)\\n\\n# Set values in DataFrame based on labels presence\\nfor review, labels in zip(reviews, llb):\\n    row_values = [1 if label in labels else 0 for label in unique_labels]\\n    df_new.loc[len(df_new)] = [review] + row_values\\n\\n# Save DataFrame to CSV\\ndf_new.to_csv(\\'reviews_with_labels.csv\\', index=False)\\n\\nprint(\"CSV file saved successfully.\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"reviews_with_labels.csv\")\n"
      ],
      "metadata": {
        "id": "IybMLpNF_cq5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=62,problem_type=\"multi_label_classification\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FYUw4ID7ibw",
        "outputId": "f5cf259f-3bd1-4ced-85dc-37d784e227e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to('cuda')\n"
      ],
      "metadata": {
        "id": "eLszCQ_j-lL2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = list(data[\"reviews\"])\n",
        "labels = data.iloc[:, 1:].values\n",
        "X_train, X_val, y_train, y_val = train_test_split(reviews, labels, test_size=0.2)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512,return_tensors='pt')\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512,return_tensors='pt')\n"
      ],
      "metadata": {
        "id": "N-ELwW4O_Vwo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx]).float()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)\n"
      ],
      "metadata": {
        "id": "_bt2NE1kAKG8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    labels = np.argmax(labels, axis=1)\n",
        "    accuracy = accuracy_score(labels, pred)\n",
        "    recall = recall_score(labels, pred, average='weighted')\n",
        "    precision = precision_score(labels, pred, average='weighted')\n",
        "    f1 = f1_score(labels, pred, average='weighted')\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "metadata": {
        "id": "x3INwp15A6od"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=20,\n",
        "\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "pRa51OREBB6q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "MlzML1psCFK-",
        "outputId": "ed2fc746-e2a4-4665-c285-81c9904c4191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d4e3ca12e20a>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='411' max='3250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 411/3250 12:02 < 1:23:34, 0.57 it/s, Epoch 1.26/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "BwaALg3iN-q7",
        "outputId": "d97c3010-43b4-45f7-f261-253a1d6a5095"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d4e3ca12e20a>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [204/204 00:46]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.08865189552307129,\n",
              " 'eval_accuracy': 0.5563076923076923,\n",
              " 'eval_precision': 0.3143138461538461,\n",
              " 'eval_recall': 0.5563076923076923,\n",
              " 'eval_f1': 0.4016790366183337,\n",
              " 'eval_runtime': 46.4977,\n",
              " 'eval_samples_per_second': 34.948,\n",
              " 'eval_steps_per_second': 4.387,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "text = \"Great service and price from [REDACTED] let down by fitters. [REDACTED] price was by far the best I could find. While they delivered my tyres on time, their fitting garage had suffered an equipment failure and had to delay the fitting by three days. This is the only reason for me dropping my rating to four stars.\"\n",
        "inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "lbl = data.columns[1:64].tolist()\n",
        "high_prob_indices = [i for i, prob in enumerate(predictions[0]) if prob > 0.5]\n",
        "predicted_labels = [lbl[i] for i in high_prob_indices]\n",
        "output_labels = ', '.join(predicted_labels)\n",
        "print(output_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9FjXlPPNOfY",
        "outputId": "321540f4-69a8-40ad-edcc-84ba5cc678b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value for money positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = (\"Great service and price from [REDACTED] let down by fitters. [REDACTED] price was by far the best I could find. \"\n",
        "        \"While they delivered my tyres on time, their fitting garage had suffered an equipment failure and had to delay \"\n",
        "        \"the fitting by three days. This is the only reason for me dropping my rating to four stars.\")\n",
        "inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "high_prob_indices = [i for i, prob in enumerate(predictions[0]) if prob > 0.020]\n",
        "predicted_labels = [lbl[i] for i in high_prob_indices]\n",
        "output_labels = ', '.join(predicted_labels)\n",
        "print(output_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cp5LmHvUePo",
        "outputId": "1bff0197-35a7-4afd-a0d8-d7d2c133a971"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change of date negative, value for money positive, delivery punctuality positive, location positive, length of fitting positive, mobile fitter positive, ease of booking positive, garage service positive\n"
          ]
        }
      ]
    }
  ]
}
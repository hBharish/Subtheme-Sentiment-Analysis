{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMt62Vle9gKFvp8qkHtgk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hBharish/Subtheme-Sentiment-Analysis/blob/main/Subtheme_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H259LKfI7NXP"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from re import escape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Load dataset\n",
        "df = pd.read_csv('Evaluation-dataset.csv')\n",
        "df = df.dropna(subset=[df.columns[1]])\n",
        "\n",
        "# Initialize lists to store reviews and labels\n",
        "reviews = []\n",
        "unique_labels = set()\n",
        "llb = []\n",
        "\n",
        "# Iterate over each row in the dataset\n",
        "for row in df.itertuples(index=False):\n",
        "    temp_labels = []\n",
        "    for item in row[1:]:\n",
        "        if pd.notnull(item):\n",
        "            if \"positive\" in item.lower() or \"negative\" in item.lower():\n",
        "                unique_labels.add(item.lower())\n",
        "                temp_labels.append(item.lower())\n",
        "    if temp_labels:\n",
        "        reviews.append(row[0])\n",
        "        llb.append(temp_labels)\n",
        "\n",
        "# Convert labels set to list\n",
        "unique_labels = list(unique_labels)\n",
        "print(len(reviews))\n",
        "\n",
        "# Create DataFrame with reviews and unique labels\n",
        "df_new = pd.DataFrame(columns=['reviews'] + unique_labels)\n",
        "\n",
        "# Set values in DataFrame based on labels presence\n",
        "for review, labels in zip(reviews, llb):\n",
        "    row_values = [1 if label in labels else 0 for label in unique_labels]\n",
        "    df_new.loc[len(df_new)] = [review] + row_values\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "df_new.to_csv('reviews_with_labels.csv', index=False)\n",
        "\n",
        "print(\"CSV file saved successfully.\")'''"
      ],
      "metadata": {
        "id": "l9UGWPqb7eR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"reviews_with_labels.csv\")\n"
      ],
      "metadata": {
        "id": "IybMLpNF_cq5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=62,problem_type=\"multi_label_classification\")\n"
      ],
      "metadata": {
        "id": "6FYUw4ID7ibw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to('cuda')\n"
      ],
      "metadata": {
        "id": "eLszCQ_j-lL2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = list(data[\"reviews\"])\n",
        "labels = data.iloc[:, 1:].values\n",
        "X_train, X_val, y_train, y_val = train_test_split(reviews, labels, test_size=0.2)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512,return_tensors='pt')\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512,return_tensors='pt')\n"
      ],
      "metadata": {
        "id": "N-ELwW4O_Vwo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx]).float()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)\n"
      ],
      "metadata": {
        "id": "_bt2NE1kAKG8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    labels = np.argmax(labels, axis=1)\n",
        "    accuracy = accuracy_score(labels, pred)\n",
        "    recall = recall_score(labels, pred, average='weighted')\n",
        "    precision = precision_score(labels, pred, average='weighted')\n",
        "    f1 = f1_score(labels, pred, average='weighted')\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "metadata": {
        "id": "x3INwp15A6od"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=20,\n",
        "\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "pRa51OREBB6q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "MlzML1psCFK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "BwaALg3iN-q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = (\"Great service and price from [REDACTED] let down by fitters. [REDACTED] price was by far the best I could find. \"\n",
        "        \"While they delivered my tyres on time, their fitting garage had suffered an equipment failure and had to delay \"\n",
        "        \"the fitting by three days. This is the only reason for me dropping my rating to four stars.\")\n",
        "inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "high_prob_indices = [i for i, prob in enumerate(predictions[0]) if prob > 0.020]\n",
        "predicted_labels = [lbl[i] for i in high_prob_indices]\n",
        "output_labels = ', '.join(predicted_labels)\n",
        "print(output_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cp5LmHvUePo",
        "outputId": "1bff0197-35a7-4afd-a0d8-d7d2c133a971"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change of date negative, value for money positive, delivery punctuality positive, location positive, length of fitting positive, mobile fitter positive, ease of booking positive, garage service positive\n"
          ]
        }
      ]
    }
  ]
}